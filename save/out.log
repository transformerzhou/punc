2021-07-13 08:45:30,629 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2021-07-13 08:45:30,629 - INFO - allennlp.common.params - dataset_reader.type = data_reader
2021-07-13 08:45:30,629 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2021-07-13 08:45:30,629 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = hfl/chinese-roberta-wwm-ext-large
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None
2021-07-13 08:45:30,630 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None
2021-07-13 08:45:43,865 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer
2021-07-13 08:45:43,865 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-07-13 08:45:43,865 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = hfl/chinese-roberta-wwm-ext-large
2021-07-13 08:45:43,865 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags
2021-07-13 08:45:43,865 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = None
2021-07-13 08:45:43,866 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None
2021-07-13 08:45:43,866 - INFO - allennlp.common.params - dataset_reader.max_tokens = 512
2021-07-13 08:45:43,866 - INFO - allennlp.common.params - dataset_reader.text_num = 2000
2021-07-13 08:45:43,866 - INFO - allennlp.common.params - train_data_path = ['./data/BCUT/train.txt', './data/translation_zh/translation_zh.dev.txt', './data/wiki_cut/wiki_train.txt']
2021-07-13 08:45:43,867 - INFO - allennlp.training.util - Reading training data from ['./data/BCUT/train.txt', './data/translation_zh/translation_zh.dev.txt', './data/wiki_cut/wiki_train.txt']
2021-07-13 08:45:43,867 - INFO - allennlp.common.params - data_loader.type = multiprocess
2021-07-13 08:45:43,867 - INFO - allennlp.common.params - data_loader.batch_size = None
2021-07-13 08:45:43,867 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-07-13 08:45:43,867 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-07-13 08:45:43,867 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 8
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.num_workers = 8
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.start_method = fork
2021-07-13 08:45:43,868 - INFO - allennlp.common.params - data_loader.cuda_device = None
2021-07-13 08:45:43,869 - INFO - allennlp.common.params - data_loader.quiet = False
2021-07-13 08:45:43,908 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2021-07-13 08:45:54,105 - INFO - tqdm - loading instances: 5947it [00:10, 780.12it/s]
2021-07-13 08:45:54,397 - INFO - allennlp.common.params - validation_dataset_reader = None
2021-07-13 08:45:54,398 - INFO - allennlp.common.params - validation_data_loader = data_loader.Params({'batch_sampler': {'batch_size': 8, 'sorting_keys': ['text'], 'type': 'bucket'}, 'num_workers': 8})
2021-07-13 08:45:54,398 - INFO - allennlp.common.params - validation_data_path = ['data/BCUT/test.txt']
2021-07-13 08:45:54,398 - INFO - allennlp.training.util - Reading validation data from ['data/BCUT/test.txt']
2021-07-13 08:45:54,398 - INFO - allennlp.common.params - data_loader.type = multiprocess
2021-07-13 08:45:54,399 - INFO - allennlp.common.params - data_loader.batch_size = None
2021-07-13 08:45:54,399 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-07-13 08:45:54,399 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 8
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = ['text']
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-07-13 08:45:54,400 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-07-13 08:45:54,401 - INFO - allennlp.common.params - data_loader.num_workers = 8
2021-07-13 08:45:54,401 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2021-07-13 08:45:54,401 - INFO - allennlp.common.params - data_loader.start_method = fork
2021-07-13 08:45:54,401 - INFO - allennlp.common.params - data_loader.cuda_device = None
2021-07-13 08:45:54,401 - INFO - allennlp.common.params - data_loader.quiet = False
2021-07-13 08:45:54,473 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2021-07-13 08:45:55,370 - INFO - allennlp.common.params - vocabulary.type = from_instances
2021-07-13 08:45:55,371 - INFO - allennlp.common.params - vocabulary.min_count = None
2021-07-13 08:45:55,371 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2021-07-13 08:45:55,371 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2021-07-13 08:45:55,371 - INFO - allennlp.common.params - vocabulary.pretrained_files = None
2021-07-13 08:45:55,372 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2021-07-13 08:45:55,372 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2021-07-13 08:45:55,372 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2021-07-13 08:45:55,372 - INFO - allennlp.common.params - vocabulary.padding_token = @@PADDING@@
2021-07-13 08:45:55,372 - INFO - allennlp.common.params - vocabulary.oov_token = @@UNKNOWN@@
2021-07-13 08:45:55,372 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2021-07-13 08:45:55,372 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2021-07-13 08:45:55,526 - INFO - allennlp.training.util - writing the vocabulary to save/vocabulary.
2021-07-13 08:45:55,567 - INFO - allennlp.training.util - done creating vocab
2021-07-13 08:45:55,716 - INFO - root - Switching to distributed training mode since multiple GPUs are configured | Primary is at: 127.0.0.1:33445 | Rank of this node: 0 | Number of workers in this node: 2 | Number of nodes: 1 | World size: 2
